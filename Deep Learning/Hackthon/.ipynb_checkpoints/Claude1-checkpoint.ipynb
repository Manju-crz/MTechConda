{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66cec9b-718f-4366-b7c2-2c7c3c5660a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, EfficientNetB0\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "class FakeRealImageDetector:\n",
    "    def __init__(self, dataset_path, test_path, train_csv_path, test_csv_path):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.test_path = test_path\n",
    "        self.train_csv_path = train_csv_path\n",
    "        self.test_csv_path = test_csv_path\n",
    "        self.img_size = (224, 224)\n",
    "        self.batch_size = 32\n",
    "        self.epochs = 50\n",
    "        \n",
    "        # Load CSV files\n",
    "        self.train_df = pd.read_csv(train_csv_path)\n",
    "        self.test_df = pd.read_csv(test_csv_path)\n",
    "        \n",
    "        print(f\"Training samples: {len(self.train_df)}\")\n",
    "        print(f\"Test samples: {len(self.test_df)}\")\n",
    "        print(f\"Class distribution in training data:\")\n",
    "        print(self.train_df['label'].value_counts())\n",
    "    \n",
    "    def load_and_preprocess_data(self):\n",
    "        \"\"\"Load and preprocess training and test data\"\"\"\n",
    "        print(\"Loading and preprocessing data...\")\n",
    "        \n",
    "        # Load training data\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        \n",
    "        for idx, row in self.train_df.iterrows():\n",
    "            filename = row['filename']\n",
    "            label = row['label']\n",
    "            \n",
    "            # Determine the correct folder based on label\n",
    "            if label == 'real':\n",
    "                img_path = os.path.join(self.dataset_path, 'training_real', filename)\n",
    "            else:\n",
    "                img_path = os.path.join(self.dataset_path, 'training_fake', filename)\n",
    "            \n",
    "            if os.path.exists(img_path):\n",
    "                # Load and preprocess image\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is not None:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    img = cv2.resize(img, self.img_size)\n",
    "                    img = img.astype('float32') / 255.0\n",
    "                    \n",
    "                    X_train.append(img)\n",
    "                    y_train.append(1 if label == 'real' else 0)\n",
    "        \n",
    "        # Load test data\n",
    "        X_test = []\n",
    "        test_filenames = []\n",
    "        \n",
    "        for idx, row in self.test_df.iterrows():\n",
    "            filename = row['filename']\n",
    "            img_path = os.path.join(self.test_path, filename)\n",
    "            \n",
    "            if os.path.exists(img_path):\n",
    "                # Load and preprocess image\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is not None:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    img = cv2.resize(img, self.img_size)\n",
    "                    img = img.astype('float32') / 255.0\n",
    "                    \n",
    "                    X_test.append(img)\n",
    "                    test_filenames.append(filename)\n",
    "        \n",
    "        # Convert to numpy arrays\n",
    "        X_train = np.array(X_train)\n",
    "        y_train = np.array(y_train)\n",
    "        X_test = np.array(X_test)\n",
    "        \n",
    "        # Split training data into train and validation\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    "        )\n",
    "        \n",
    "        print(f\"Training set shape: {X_train.shape}\")\n",
    "        print(f\"Validation set shape: {X_val.shape}\")\n",
    "        print(f\"Test set shape: {X_test.shape}\")\n",
    "        \n",
    "        return X_train, X_val, X_test, y_train, y_val, test_filenames\n",
    "    \n",
    "    def create_custom_cnn_model(self):\n",
    "        \"\"\"Create a custom CNN model from scratch\"\"\"\n",
    "        model = Sequential([\n",
    "            # First Convolutional Block\n",
    "            Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            \n",
    "            # Second Convolutional Block\n",
    "            Conv2D(64, (3, 3), activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            \n",
    "            # Third Convolutional Block\n",
    "            Conv2D(128, (3, 3), activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            \n",
    "            # Fourth Convolutional Block\n",
    "            Conv2D(256, (3, 3), activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            \n",
    "            # Fifth Convolutional Block\n",
    "            Conv2D(512, (3, 3), activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            \n",
    "            # Flatten and Dense layers\n",
    "            Flatten(),\n",
    "            Dense(512, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(256, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dropout(0.3),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def create_vgg16_model(self):\n",
    "        \"\"\"Create a model using pre-trained VGG16\"\"\"\n",
    "        base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "        \n",
    "        # Freeze base model layers\n",
    "        base_model.trainable = False\n",
    "        \n",
    "        model = Sequential([\n",
    "            base_model,\n",
    "            GlobalAveragePooling2D(),\n",
    "            Dense(512, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(256, activation='relu'),\n",
    "            Dropout(0.3),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def create_resnet50_model(self):\n",
    "        \"\"\"Create a model using pre-trained ResNet50\"\"\"\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "        \n",
    "        # Freeze base model layers\n",
    "        base_model.trainable = False\n",
    "        \n",
    "        model = Sequential([\n",
    "            base_model,\n",
    "            GlobalAveragePooling2D(),\n",
    "            Dense(512, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(256, activation='relu'),\n",
    "            Dropout(0.3),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def create_efficientnet_model(self):\n",
    "        \"\"\"Create a model using pre-trained EfficientNetB0\"\"\"\n",
    "        base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "        \n",
    "        # Freeze base model layers\n",
    "        base_model.trainable = False\n",
    "        \n",
    "        model = Sequential([\n",
    "            base_model,\n",
    "            GlobalAveragePooling2D(),\n",
    "            Dense(512, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(256, activation='relu'),\n",
    "            Dropout(0.3),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def create_data_generators(self, X_train, y_train):\n",
    "        \"\"\"Create data generators for data augmentation\"\"\"\n",
    "        datagen = ImageDataGenerator(\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            zoom_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            fill_mode='nearest'\n",
    "        )\n",
    "        \n",
    "        return datagen\n",
    "    \n",
    "    def train_model(self, model, X_train, X_val, y_train, y_val, model_name):\n",
    "        \"\"\"Train a model with callbacks\"\"\"\n",
    "        print(f\"\\nTraining {model_name} model...\")\n",
    "        \n",
    "        # Callbacks\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        reduce_lr = ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.2,\n",
    "            patience=5,\n",
    "            min_lr=0.0001\n",
    "        )\n",
    "        \n",
    "        model_checkpoint = ModelCheckpoint(\n",
    "            f'{model_name}_best_model.h5',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False\n",
    "        )\n",
    "        \n",
    "        # Data augmentation\n",
    "        datagen = self.create_data_generators(X_train, y_train)\n",
    "        \n",
    "        # Train the model\n",
    "        history = model.fit(\n",
    "            datagen.flow(X_train, y_train, batch_size=self.batch_size),\n",
    "            steps_per_epoch=len(X_train) // self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[early_stopping, reduce_lr, model_checkpoint],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def plot_training_history(self, history, model_name):\n",
    "        \"\"\"Plot training history\"\"\"\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.title(f'{model_name} - Model Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['loss'], label='Training Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title(f'{model_name} - Model Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def evaluate_model(self, model, X_val, y_val, model_name):\n",
    "        \"\"\"Evaluate model performance\"\"\"\n",
    "        print(f\"\\nEvaluating {model_name} model...\")\n",
    "        \n",
    "        # Predictions\n",
    "        y_pred_proba = model.predict(X_val)\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(y_val, y_pred)\n",
    "        print(f\"{model_name} Validation Accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "        # Classification report\n",
    "        print(f\"\\n{model_name} Classification Report:\")\n",
    "        print(classification_report(y_val, y_pred, target_names=['Fake', 'Real']))\n",
    "        \n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(y_val, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=['Fake', 'Real'], yticklabels=['Fake', 'Real'])\n",
    "        plt.title(f'{model_name} - Confusion Matrix')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.show()\n",
    "        \n",
    "        return accuracy\n",
    "    \n",
    "    def predict_test_data(self, model, X_test, test_filenames, model_name):\n",
    "        \"\"\"Make predictions on test data\"\"\"\n",
    "        print(f\"\\nMaking predictions with {model_name} model...\")\n",
    "        \n",
    "        # Predictions\n",
    "        y_pred_proba = model.predict(X_test)\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "        \n",
    "        # Create submission dataframe\n",
    "        submission_df = pd.DataFrame({\n",
    "            'filename': test_filenames,\n",
    "            'prediction': ['real' if pred == 1 else 'fake' for pred in y_pred],\n",
    "            'confidence': y_pred_proba.flatten()\n",
    "        })\n",
    "        \n",
    "        # Save predictions\n",
    "        submission_df.to_csv(f'{model_name}_predictions.csv', index=False)\n",
    "        print(f\"Predictions saved to {model_name}_predictions.csv\")\n",
    "        \n",
    "        return submission_df\n",
    "    \n",
    "    def run_complete_pipeline(self):\n",
    "        \"\"\"Run the complete pipeline\"\"\"\n",
    "        print(\"Starting Fake vs Real Image Detection Pipeline...\")\n",
    "        \n",
    "        # Load and preprocess data\n",
    "        X_train, X_val, X_test, y_train, y_val, test_filenames = self.load_and_preprocess_data()\n",
    "        \n",
    "        # Dictionary to store model performances\n",
    "        model_performances = {}\n",
    "        \n",
    "        # 1. Custom CNN Model\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"TRAINING CUSTOM CNN MODEL\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        custom_cnn = self.create_custom_cnn_model()\n",
    "        print(custom_cnn.summary())\n",
    "        \n",
    "        history_cnn = self.train_model(custom_cnn, X_train, X_val, y_train, y_val, \"Custom_CNN\")\n",
    "        self.plot_training_history(history_cnn, \"Custom CNN\")\n",
    "        \n",
    "        accuracy_cnn = self.evaluate_model(custom_cnn, X_val, y_val, \"Custom CNN\")\n",
    "        model_performances['Custom CNN'] = accuracy_cnn\n",
    "        \n",
    "        predictions_cnn = self.predict_test_data(custom_cnn, X_test, test_filenames, \"Custom_CNN\")\n",
    "        \n",
    "        # 2. VGG16 Model\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"TRAINING VGG16 MODEL\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        vgg16_model = self.create_vgg16_model()\n",
    "        print(vgg16_model.summary())\n",
    "        \n",
    "        history_vgg16 = self.train_model(vgg16_model, X_train, X_val, y_train, y_val, \"VGG16\")\n",
    "        self.plot_training_history(history_vgg16, \"VGG16\")\n",
    "        \n",
    "        accuracy_vgg16 = self.evaluate_model(vgg16_model, X_val, y_val, \"VGG16\")\n",
    "        model_performances['VGG16'] = accuracy_vgg16\n",
    "        \n",
    "        predictions_vgg16 = self.predict_test_data(vgg16_model, X_test, test_filenames, \"VGG16\")\n",
    "        \n",
    "        # 3. ResNet50 Model\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"TRAINING RESNET50 MODEL\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        resnet50_model = self.create_resnet50_model()\n",
    "        print(resnet50_model.summary())\n",
    "        \n",
    "        history_resnet50 = self.train_model(resnet50_model, X_train, X_val, y_train, y_val, \"ResNet50\")\n",
    "        self.plot_training_history(history_resnet50, \"ResNet50\")\n",
    "        \n",
    "        accuracy_resnet50 = self.evaluate_model(resnet50_model, X_val, y_val, \"ResNet50\")\n",
    "        model_performances['ResNet50'] = accuracy_resnet50\n",
    "        \n",
    "        predictions_resnet50 = self.predict_test_data(resnet50_model, X_test, test_filenames, \"ResNet50\")\n",
    "        \n",
    "        # 4. EfficientNetB0 Model\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"TRAINING EFFICIENTNETB0 MODEL\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        efficientnet_model = self.create_efficientnet_model()\n",
    "        print(efficientnet_model.summary())\n",
    "        \n",
    "        history_efficientnet = self.train_model(efficientnet_model, X_train, X_val, y_train, y_val, \"EfficientNetB0\")\n",
    "        self.plot_training_history(history_efficientnet, \"EfficientNetB0\")\n",
    "        \n",
    "        accuracy_efficientnet = self.evaluate_model(efficientnet_model, X_val, y_val, \"EfficientNetB0\")\n",
    "        model_performances['EfficientNetB0'] = accuracy_efficientnet\n",
    "        \n",
    "        predictions_efficientnet = self.predict_test_data(efficientnet_model, X_test, test_filenames, \"EfficientNetB0\")\n",
    "        \n",
    "        # Model Comparison\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"MODEL COMPARISON\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Display model performances\n",
    "        performance_df = pd.DataFrame(list(model_performances.items()), \n",
    "                                    columns=['Model', 'Validation Accuracy'])\n",
    "        performance_df = performance_df.sort_values('Validation Accuracy', ascending=False)\n",
    "        \n",
    "        print(\"\\nModel Performance Summary:\")\n",
    "        print(performance_df.to_string(index=False))\n",
    "        \n",
    "        # Plot model comparison\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(performance_df['Model'], performance_df['Validation Accuracy'])\n",
    "        plt.title('Model Performance Comparison')\n",
    "        plt.xlabel('Model')\n",
    "        plt.ylabel('Validation Accuracy')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.ylim(0, 1)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for i, v in enumerate(performance_df['Validation Accuracy']):\n",
    "            plt.text(i, v + 0.01, f'{v:.4f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Best model\n",
    "        best_model_name = performance_df.iloc[0]['Model']\n",
    "        best_accuracy = performance_df.iloc[0]['Validation Accuracy']\n",
    "        \n",
    "        print(f\"\\nBest performing model: {best_model_name}\")\n",
    "        print(f\"Best validation accuracy: {best_accuracy:.4f}\")\n",
    "        \n",
    "        return model_performances\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Define paths (modify these according to your folder structure)\n",
    "    dataset_path = \"dataset\"  # Contains training_real and training_fake folders\n",
    "    test_path = \"test\"        # Contains test images\n",
    "    train_csv_path = \"train.csv\"\n",
    "    test_csv_path = \"test.csv\"\n",
    "    \n",
    "    # Initialize the detector\n",
    "    detector = FakeRealImageDetector(dataset_path, test_path, train_csv_path, test_csv_path)\n",
    "    \n",
    "    # Run the complete pipeline\n",
    "    model_performances = detector.run_complete_pipeline()\n",
    "    \n",
    "    print(\"\\nPipeline completed successfully!\")\n",
    "    print(\"Check the generated CSV files for predictions from each model.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
