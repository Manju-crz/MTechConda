{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "591271b8-5faa-4ecc-8c81-3d1840e9cdb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame loaded successfully.\n",
      "        Month  Avg_sunspot_count\n",
      "0  01-01-1749                 97\n",
      "1  02-01-1749                104\n",
      "2  03-01-1749                117\n",
      "3  04-01-1749                 93\n",
      "4  05-01-1749                142\n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3144 entries, 0 to 3143\n",
      "Data columns (total 2 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Month              3144 non-null   object\n",
      " 1   Avg_sunspot_count  3144 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 49.3+ KB\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Year'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Year'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 25\u001b[0m\n\u001b[0;32m     21\u001b[0m     exit()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Assuming the CSV has columns like 'Year', 'Month', and 'Sunspot_Count'\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Let's create a proper datetime index\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonth\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m), \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m df\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Rename the sunspot count column if it's not 'Sunspot_Count'\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Based on typical sunspot datasets, it's often named 'monthly_average_sunspot_count' or similar.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Let's check the columns and assume the last numeric column is the sunspot count if not explicitly named.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Year'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from prophet import Prophet\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- 1. Load and Explore Data ---\n",
    "try:\n",
    "    df = pd.read_csv('train.csv')\n",
    "    print(\"DataFrame loaded successfully.\")\n",
    "    print(df.head())\n",
    "    print(\"\\nDataFrame Info:\")\n",
    "    df.info()\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: train.csv not found. Please ensure the file is in the correct directory.\")\n",
    "    exit()\n",
    "\n",
    "# Assuming the CSV has columns like 'Year', 'Month', and 'Sunspot_Count'\n",
    "# Let's create a proper datetime index\n",
    "df['Date'] = pd.to_datetime(df['Year'].astype(str) + '-' + df['Month'].astype(str), format='%Y-%m')\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Rename the sunspot count column if it's not 'Sunspot_Count'\n",
    "# Based on typical sunspot datasets, it's often named 'monthly_average_sunspot_count' or similar.\n",
    "# Let's check the columns and assume the last numeric column is the sunspot count if not explicitly named.\n",
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "if 'Sunspot_Count' not in df.columns and len(numeric_cols) > 0:\n",
    "    # Assuming the last numeric column after Year and Month (which we used for index) is the sunspot count\n",
    "    # Let's be more robust: find the column that looks like sunspot data\n",
    "    sunspot_col_candidates = [col for col in numeric_cols if col not in ['Year', 'Month']]\n",
    "    if sunspot_col_candidates:\n",
    "        df = df.rename(columns={sunspot_col_candidates[-1]: 'Sunspot_Count'})\n",
    "        print(f\"\\nRenamed column '{sunspot_col_candidates[-1]}' to 'Sunspot_Count'.\")\n",
    "    else:\n",
    "        print(\"\\nCould not identify a suitable 'Sunspot_Count' column. Please check your CSV column names.\")\n",
    "        exit()\n",
    "elif 'Sunspot_Count' not in df.columns:\n",
    "     print(\"\\nError: 'Sunspot_Count' column not found and could not be inferred. Please check your CSV column names.\")\n",
    "     exit()\n",
    "\n",
    "# Select only the target variable for time series analysis\n",
    "ts = df['Sunspot_Count'].asfreq('MS') # 'MS' for Month Start frequency\n",
    "\n",
    "print(f\"\\nTime series shape: {ts.shape}\")\n",
    "print(f\"Time series start: {ts.index.min()}\")\n",
    "print(f\"Time series end: {ts.index.max()}\")\n",
    "\n",
    "# Visualize the time series\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(ts)\n",
    "plt.title('Monthly Average Sunspot Count (1749-2010)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sunspot Count')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Decompose the time series to observe trend, seasonality, and residuals\n",
    "# Given the data spans centuries, a strong seasonal component (approx 11 years) is expected.\n",
    "# Let's assume a yearly seasonality for decomposition for simplicity, as monthly data is given.\n",
    "# For sunspots, the cycle is ~11 years, so a true 'seasonal' component might be longer.\n",
    "# However, `seasonal_decompose` typically looks for shorter, fixed-period seasonality.\n",
    "# We'll use additive model as sunspot counts are absolute.\n",
    "decomposition = seasonal_decompose(ts, model='additive', period=12) # Period 12 for yearly seasonality\n",
    "fig = decomposition.plot()\n",
    "fig.set_size_inches(12, 8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot ACF and PACF to help identify AR and MA components for SARIMA\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.subplot(211)\n",
    "plot_acf(ts, lags=50, ax=plt.gca(), title='Autocorrelation Function (ACF)')\n",
    "plt.subplot(212)\n",
    "plot_pacf(ts, lags=50, ax=plt.gca(), title='Partial Autocorrelation Function (PACF)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- 2. Data Preprocessing (already done by setting index and frequency) ---\n",
    "# The data is already monthly, so asfreq('MS') handles any missing frequencies by filling with NaN.\n",
    "# Check for NaNs\n",
    "print(f\"\\nNumber of NaNs in time series: {ts.isnull().sum()}\")\n",
    "# If there were NaNs, you'd typically handle them with interpolation:\n",
    "# ts = ts.interpolate(method='time') # if NaNs exist\n",
    "\n",
    "# --- 3. Model Selection and Training ---\n",
    "\n",
    "# Define the training data (up to 2010)\n",
    "train_data = ts[ts.index.year <= 2010]\n",
    "print(f\"\\nTraining data ends: {train_data.index.max()}\")\n",
    "\n",
    "# --- Model 1: SARIMA (Seasonal AutoRegressive Integrated Moving Average) ---\n",
    "# Sunspot data is known to have an ~11-year cycle, so seasonal_order (P,D,Q,S) will be important.\n",
    "# S=12 for monthly data (yearly seasonality). For the 11-year cycle, S could be 12*11=132,\n",
    "# but `seasonal_decompose` and `SARIMAX` with S=12 can capture shorter-term seasonality.\n",
    "# To capture the 11-year cycle, we might need a very high seasonal order or a different approach.\n",
    "# Let's start with a standard yearly seasonality (P,D,Q,12) and see.\n",
    "# The ACF/PACF plots can help determine p, d, q, P, D, Q.\n",
    "# A common approach is to try a few orders and use AIC/BIC to compare.\n",
    "\n",
    "# For sunspots, a common SARIMA model might involve differencing (d=1 or 2) and seasonal differencing (D=1).\n",
    "# Given the clear cycles, P, Q, p, q might also be non-zero.\n",
    "# Let's try some common parameters first, and for a production model, you'd perform grid search.\n",
    "\n",
    "# Example SARIMA parameters (these are often tuned):\n",
    "# order=(p,d,q) - non-seasonal components\n",
    "# seasonal_order=(P,D,Q,S) - seasonal components\n",
    "# S=12 for monthly data, representing yearly seasonality.\n",
    "# A more accurate seasonal period for sunspots could be 132 (11 years * 12 months).\n",
    "# However, SARIMAX with a very large seasonal period can be computationally intensive.\n",
    "# Let's try S=12, and acknowledge that the 11-year cycle is harder to capture perfectly with this S.\n",
    "\n",
    "print(\"\\n--- Training SARIMA Model ---\")\n",
    "try:\n",
    "    sarima_model = SARIMAX(train_data,\n",
    "                            order=(1, 1, 1), # Example non-seasonal order\n",
    "                            seasonal_order=(1, 1, 1, 12), # Example seasonal order (P,D,Q,S)\n",
    "                            enforce_stationarity=False,\n",
    "                            enforce_invertibility=False)\n",
    "    sarima_results = sarima_model.fit(disp=False)\n",
    "    print(sarima_results.summary())\n",
    "except Exception as e:\n",
    "    print(f\"Error training SARIMA model: {e}\")\n",
    "    print(\"SARIMA might struggle with very long cycles or non-stationary data. Consider differencing more or trying different orders.\")\n",
    "\n",
    "# --- Model 2: Facebook Prophet ---\n",
    "# Prophet is designed for business forecasting and handles multiple seasonality (daily, weekly, yearly)\n",
    "# automatically and is robust to missing data and outliers. It requires columns 'ds' (datetime) and 'y' (value).\n",
    "print(\"\\n--- Training Prophet Model ---\")\n",
    "prophet_df = train_data.reset_index()\n",
    "prophet_df = prophet_df.rename(columns={'Date': 'ds', 'Sunspot_Count': 'y'})\n",
    "\n",
    "# Instantiate and fit the model\n",
    "prophet_model = Prophet(\n",
    "    growth='linear',\n",
    "    seasonality_mode='additive',\n",
    "    yearly_seasonality=True, # Prophet will try to detect yearly seasonality\n",
    "    weekly_seasonality=False, # Monthly data, no weekly\n",
    "    daily_seasonality=False,  # Monthly data, no daily\n",
    "    seasonality_prior_scale=10, # Adjust for stronger seasonality\n",
    "    changepoint_prior_scale=0.05 # Adjust for more flexibility in trend changes\n",
    ")\n",
    "\n",
    "# For sunspot data, a custom seasonality might be beneficial to capture the ~11 year cycle\n",
    "# Here's how you could add it:\n",
    "prophet_model.add_seasonality(name='sunspot_cycle', period=11*12, fourier_order=10) # 11 years * 12 months\n",
    "\n",
    "prophet_model.fit(prophet_df)\n",
    "\n",
    "# --- 4. Forecasting ---\n",
    "\n",
    "# Define the forecast period (2011-2020)\n",
    "forecast_start_date = '2011-01-01'\n",
    "forecast_end_date = '2020-12-01'\n",
    "forecast_dates = pd.date_range(start=forecast_start_date, end=forecast_end_date, freq='MS')\n",
    "print(f\"\\nForecast period: {forecast_start_date} to {forecast_end_date}\")\n",
    "print(f\"Number of forecast months: {len(forecast_dates)}\")\n",
    "\n",
    "# --- SARIMA Forecast ---\n",
    "sarima_forecast = pd.Series() # Initialize an empty series\n",
    "\n",
    "if 'sarima_results' in locals():\n",
    "    try:\n",
    "        sarima_forecast_res = sarima_results.predict(start=forecast_start_date, end=forecast_end_date)\n",
    "        sarima_forecast = sarima_forecast_res.rename('SARIMA_Forecast')\n",
    "        print(\"\\nSARIMA Forecast (first 5 values):\\n\", sarima_forecast.head())\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating SARIMA forecast: {e}\")\n",
    "        sarima_forecast = pd.Series(index=forecast_dates, dtype=float) # Empty forecast if error\n",
    "\n",
    "\n",
    "# --- Prophet Forecast ---\n",
    "future_prophet = prophet_model.make_future_dataframe(periods=len(forecast_dates), freq='MS')\n",
    "prophet_forecast = prophet_model.predict(future_prophet)\n",
    "\n",
    "# Filter Prophet forecast to just the forecast period\n",
    "prophet_forecast_period = prophet_forecast[(prophet_forecast['ds'] >= forecast_start_date) &\n",
    "                                           (prophet_forecast['ds'] <= forecast_end_date)]\n",
    "\n",
    "prophet_forecast_values = prophet_forecast_period[['ds', 'yhat']].set_index('ds')['yhat'].rename('Prophet_Forecast')\n",
    "print(\"\\nProphet Forecast (first 5 values):\\n\", prophet_forecast_values.head())\n",
    "\n",
    "# --- 5. Visualization ---\n",
    "\n",
    "plt.figure(figsize=(18, 9))\n",
    "plt.plot(train_data, label='Historical Data (1749-2010)')\n",
    "\n",
    "if not sarima_forecast.empty:\n",
    "    plt.plot(sarima_forecast, label='SARIMA Forecast (2011-2020)', color='orange', linestyle='--')\n",
    "else:\n",
    "    print(\"\\nSARIMA forecast not available due to errors during training/forecasting.\")\n",
    "\n",
    "if not prophet_forecast_values.empty:\n",
    "    plt.plot(prophet_forecast_values, label='Prophet Forecast (2011-2020)', color='green', linestyle='-.')\n",
    "else:\n",
    "    print(\"\\nProphet forecast not available due to errors during training/forecasting.\")\n",
    "\n",
    "plt.title('Monthly Average Sunspot Count Forecast')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sunspot Count')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Display the forecasted values\n",
    "print(\"\\n--- Predicted Monthly Average Sunspot Count (2011-2020) ---\")\n",
    "print(\"\\nSARIMA Forecast:\")\n",
    "print(sarima_forecast.to_string())\n",
    "\n",
    "print(\"\\nProphet Forecast:\")\n",
    "print(prophet_forecast_values.to_string())\n",
    "\n",
    "# Save forecasts to CSV if needed\n",
    "sarima_forecast.to_csv('sarima_sunspot_forecast_2011_2020.csv', header=True)\n",
    "prophet_forecast_values.to_csv('prophet_sunspot_forecast_2011_2020.csv', header=True)\n",
    "print(\"\\nForecasts saved to 'sarima_sunspot_forecast_2011_2020.csv' and 'prophet_sunspot_forecast_2011_2020.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad1f5c5-e72a-48f1-a0c8-44d71dacd035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
