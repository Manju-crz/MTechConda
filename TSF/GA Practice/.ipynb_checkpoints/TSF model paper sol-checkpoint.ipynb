{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDpRBgr392kE"
   },
   "source": [
    "# Time Series - 1 Graded assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wb4GhWle92kL"
   },
   "source": [
    "### DATA_SET:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analytics firm wants to forecast the Price of Mindtree Ltd. stock for the month of Dec 2021. For this, firm has gathered a Closing Stock Price data for the period of Dec 2020 to Nov 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LED0-S192kT"
   },
   "source": [
    "* date ==\t\t\tdate field\t\n",
    "* Closing == \t    Daily Closing Price of Stock (numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wVAVAxL_92k5"
   },
   "source": [
    "#### 1.\tData preparation (5 marks)\n",
    "\n",
    "\n",
    "a.\tRead the dataset (tab, csv, xls, txt, inbuilt dataset). What are the number of rows and no. of cols & types of variables? (1 MARK)\n",
    "\n",
    "b. convert the data into time series (2 MARK)\n",
    "\n",
    "\n",
    "c. Check for defects in the data such as missing values, null, etc. (1 MARK)\n",
    "\n",
    "d. Visualize the time series using relevant plots. (1 MARK)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "G4pGllot92k8"
   },
   "outputs": [],
   "source": [
    "import pandas                             as      pd\n",
    "import numpy                              as      np\n",
    "import matplotlib.pyplot                  as      plt\n",
    "import seaborn                            as      sns\n",
    "from   pylab                              import  rcParams \n",
    "from   datetime                           import  datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "df=pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Closing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04-12-2020</td>\n",
       "      <td>1411.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07-12-2020</td>\n",
       "      <td>1414.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08-12-2020</td>\n",
       "      <td>1441.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>09-12-2020</td>\n",
       "      <td>1437.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10-12-2020</td>\n",
       "      <td>1442.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Closing\n",
       "0  04-12-2020  1411.60\n",
       "1  07-12-2020  1414.30\n",
       "2  08-12-2020  1441.70\n",
       "3  09-12-2020  1437.95\n",
       "4  10-12-2020  1442.70"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Closing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>25-11-2021</td>\n",
       "      <td>4576.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>26-11-2021</td>\n",
       "      <td>4597.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>29-11-2021</td>\n",
       "      <td>4625.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>30-11-2021</td>\n",
       "      <td>4547.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>01-12-2021</td>\n",
       "      <td>4591.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Closing\n",
       "254  25-11-2021  4576.55\n",
       "255  26-11-2021  4597.90\n",
       "256  29-11-2021  4625.55\n",
       "257  30-11-2021  4547.35\n",
       "258  01-12-2021  4591.05"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 259 entries, 0 to 258\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   Date     259 non-null    object \n",
      " 1   Closing  259 non-null    float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 4.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2020-12-04', '2020-12-07', '2020-12-08', '2020-12-09',\n",
       "               '2020-12-10', '2020-12-11', '2020-12-14', '2020-12-15',\n",
       "               '2020-12-16', '2020-12-17',\n",
       "               ...\n",
       "               '2021-11-18', '2021-11-19', '2021-11-22', '2021-11-23',\n",
       "               '2021-11-24', '2021-11-25', '2021-11-26', '2021-11-29',\n",
       "               '2021-11-30', '2021-12-01'],\n",
       "              dtype='datetime64[ns]', length=259, freq='B')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas.tseries.offsets import BDay\n",
    "date = pd.date_range(start='12/04/2020', end='12/01/2021', freq=BDay())\n",
    "date[0:263]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04',\n",
       "               '2018-01-05', '2018-01-06', '2018-01-07', '2018-01-08',\n",
       "               '2018-01-09', '2018-01-10',\n",
       "               ...\n",
       "               '2019-04-01', '2019-04-02', '2019-04-03', '2019-04-04',\n",
       "               '2019-04-05', '2019-04-06', '2019-04-07', '2019-04-08',\n",
       "               '2019-04-09', '2019-04-10'],\n",
       "              dtype='datetime64[ns]', length=465, freq='D')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = pd.date_range(start='1/1/2018', end='4/10/2019', freq='D')\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Closing</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeStamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-12-04</th>\n",
       "      <td>1411.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-07</th>\n",
       "      <td>1414.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-08</th>\n",
       "      <td>1441.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-09</th>\n",
       "      <td>1437.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-10</th>\n",
       "      <td>1442.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-25</th>\n",
       "      <td>4576.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-26</th>\n",
       "      <td>4597.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-29</th>\n",
       "      <td>4625.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30</th>\n",
       "      <td>4547.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-01</th>\n",
       "      <td>4591.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>259 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Closing\n",
       "TimeStamp          \n",
       "2020-12-04  1411.60\n",
       "2020-12-07  1414.30\n",
       "2020-12-08  1441.70\n",
       "2020-12-09  1437.95\n",
       "2020-12-10  1442.70\n",
       "...             ...\n",
       "2021-11-25  4576.55\n",
       "2021-11-26  4597.90\n",
       "2021-11-29  4625.55\n",
       "2021-11-30  4547.35\n",
       "2021-12-01  4591.05\n",
       "\n",
       "[259 rows x 1 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TimeStamp'] = pd.to_datetime(df['Date'], format='%d-%m-%Y')\n",
    "\n",
    "#df['TimeStamp']=pd.DataFrame(date,columns=['date'])\n",
    "df = df.set_index('TimeStamp')\n",
    "df=df.drop('Date',axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Closing    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='TimeStamp'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15,8\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Evqx7ksA92lT"
   },
   "source": [
    "#### 2.\tData understanding (15 marks)\n",
    "\n",
    "a.\tDecompose the time series and check for time series components. (4 marks)\n",
    "\n",
    "b.\tPerform dicky fuller test to check the stationarity? What other actions will you take if series is non-stationary?(3+1 marks)\n",
    "\n",
    "c.\tPlot AutoCorrelation and Partial AutoCorrelation function? What is your inference from these plots? (2+2 marks)\n",
    "\n",
    "d.\tSplit dataset into train and test sets. Use last two month data for testing. (3 marks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### a. Decompose the time series and check for time series components. (4 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "mh4DNy4l92lX"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal             import  seasonal_decompose\n",
    "decomposition = seasonal_decompose(df,model='additive')\n",
    "decomposition.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### b. Perform dicky fuller test to check the stationarity? What other actions will you take if series is non-stationary?(3+1 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.007528997627653904),\n",
       " np.float64(0.9579049966158176),\n",
       " 0,\n",
       " 258,\n",
       " {'1%': np.float64(-3.455952927706342),\n",
       "  '5%': np.float64(-2.8728086526320302),\n",
       "  '10%': np.float64(-2.572774990685656)},\n",
       " np.float64(2770.616012349057))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools            import  adfuller\n",
    "observations= df.values\n",
    "test_result = adfuller(observations)\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "####series is non-stationary. applying 1st order differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-15.394908823574541),\n",
       " np.float64(3.2726341074582285e-28),\n",
       " 0,\n",
       " 257,\n",
       " {'1%': np.float64(-3.4560535712549925),\n",
       "  '5%': np.float64(-2.8728527662442334),\n",
       "  '10%': np.float64(-2.5727985212493754)},\n",
       " np.float64(2759.816026154356))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_diff = df.diff(periods=1).dropna()\n",
    "observations= df_diff.values\n",
    "test_result = adfuller(observations)\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### c. Plot AutoCorrelation and Partial AutoCorrelation function? What is your inference from these plots? (2+2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import  plot_acf,plot_pacf\n",
    "plot_acf(df,lags=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(df,lags=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Original series is showing AR characteristics as ACF plot is decaying slowly, while PACF is showing limited number of spikes before cut-off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### d. Split dataset into train and test sets. Use last two month data for testing. (3 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_end=datetime(2020,7,30)\n",
    "test_end=datetime(2020,9,1)\n",
    "train             = df[:train_end] \n",
    "test              = df[train_end + timedelta(days=1):test_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAVdTKBS92ls"
   },
   "source": [
    "\n",
    "### 3.\tModel Building (20 marks)\n",
    "\n",
    "a.\tFit a base model and observe the residuals, RMSE and MAPE values of the model. Please comment on whether it is good or not.  (5 marks)\n",
    "\n",
    "c.\tHow would you improve the model? What changes you will make in the base model. Fit the final model.   (10 marks)\n",
    "\n",
    "d.\tAnalyze the residuals of final model. Feel free to use charts or graphs to explain. (2 marks) \n",
    "\n",
    "e.\tForecast the Close price for next 1 months using the final model? (3 marks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model using ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "pc6Zny9Y92lu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter combinations for the Model\n",
      "Model: (0, 0, 1)\n",
      "Model: (0, 0, 2)\n",
      "Model: (0, 0, 3)\n",
      "Model: (0, 1, 0)\n",
      "Model: (0, 1, 1)\n",
      "Model: (0, 1, 2)\n",
      "Model: (0, 1, 3)\n",
      "Model: (1, 0, 0)\n",
      "Model: (1, 0, 1)\n",
      "Model: (1, 0, 2)\n",
      "Model: (1, 0, 3)\n",
      "Model: (1, 1, 0)\n",
      "Model: (1, 1, 1)\n",
      "Model: (1, 1, 2)\n",
      "Model: (1, 1, 3)\n",
      "Model: (2, 0, 0)\n",
      "Model: (2, 0, 1)\n",
      "Model: (2, 0, 2)\n",
      "Model: (2, 0, 3)\n",
      "Model: (2, 1, 0)\n",
      "Model: (2, 1, 1)\n",
      "Model: (2, 1, 2)\n",
      "Model: (2, 1, 3)\n",
      "Model: (3, 0, 0)\n",
      "Model: (3, 0, 1)\n",
      "Model: (3, 0, 2)\n",
      "Model: (3, 0, 3)\n",
      "Model: (3, 1, 0)\n",
      "Model: (3, 1, 1)\n",
      "Model: (3, 1, 2)\n",
      "Model: (3, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.arima_model import  ARIMA\n",
    "import itertools\n",
    "p = q = range(0, 4)\n",
    "d= range(0,2)\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "print('parameter combinations for the Model')\n",
    "for i in range(1,len(pdq)):\n",
    "    print('Model: {}'.format(pdq[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param</th>\n",
       "      <th>AIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [param, AIC]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfObj1 = pd.DataFrame(columns=['param', 'AIC'])\n",
    "dfObj1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in pdq:\n",
    "            try:\n",
    "                mod = ARIMA(train, order=param)\n",
    "                results_Arima = mod.fit()\n",
    "                print('ARIMA{} - AIC:{}'.format(param, results_Arima.aic))\n",
    "                dfObj1 = dfObj1.append({'param':param, 'AIC': results_Arima.aic}, ignore_index=True)\n",
    "\n",
    "            except:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param</th>\n",
       "      <th>AIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [param, AIC]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfObj1.sort_values(by=['AIC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manju\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\manju\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\manju\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Schur decomposition solver error.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msm\u001b[39;00m\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mtsa\u001b[38;5;241m.\u001b[39marima\u001b[38;5;241m.\u001b[39mARIMA(train, order\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m----> 4\u001b[0m results_Arima \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(results_Arima\u001b[38;5;241m.\u001b[39msummary())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\arima\\model.py:395\u001b[0m, in \u001b[0;36mARIMA.fit\u001b[1;34m(self, start_params, transformed, includes_fixed, method, method_kwargs, gls, gls_kwargs, cov_type, cov_kwds, return_params, low_memory)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    393\u001b[0m     method_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 395\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    396\u001b[0m         return_params\u001b[38;5;241m=\u001b[39mreturn_params, low_memory\u001b[38;5;241m=\u001b[39mlow_memory,\n\u001b[0;32m    397\u001b[0m         cov_type\u001b[38;5;241m=\u001b[39mcov_type, cov_kwds\u001b[38;5;241m=\u001b[39mcov_kwds, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmethod_kwargs)\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_params:\n\u001b[0;32m    399\u001b[0m         res\u001b[38;5;241m.\u001b[39mfit_details \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mmlefit\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:705\u001b[0m, in \u001b[0;36mMLEModel.fit\u001b[1;34m(self, start_params, transformed, includes_fixed, cov_type, cov_kwds, method, maxiter, full_output, disp, callback, return_params, optim_score, optim_complex_step, optim_hessian, flags, low_memory, **kwargs)\u001b[0m\n\u001b[0;32m    703\u001b[0m         flags[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhessian_method\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m optim_hessian\n\u001b[0;32m    704\u001b[0m     fargs \u001b[38;5;241m=\u001b[39m (flags,)\n\u001b[1;32m--> 705\u001b[0m     mlefit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(start_params, method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    706\u001b[0m                          fargs\u001b[38;5;241m=\u001b[39mfargs,\n\u001b[0;32m    707\u001b[0m                          maxiter\u001b[38;5;241m=\u001b[39mmaxiter,\n\u001b[0;32m    708\u001b[0m                          full_output\u001b[38;5;241m=\u001b[39mfull_output,\n\u001b[0;32m    709\u001b[0m                          disp\u001b[38;5;241m=\u001b[39mdisp, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    710\u001b[0m                          skip_hessian\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    712\u001b[0m \u001b[38;5;66;03m# Just return the fitted parameters if requested\u001b[39;00m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_params:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:566\u001b[0m, in \u001b[0;36mLikelihoodModel.fit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_t\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    565\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Optimizer()\n\u001b[1;32m--> 566\u001b[0m xopt, retvals, optim_settings \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39m_fit(f, score, start_params,\n\u001b[0;32m    567\u001b[0m                                                fargs, kwargs,\n\u001b[0;32m    568\u001b[0m                                                hessian\u001b[38;5;241m=\u001b[39mhess,\n\u001b[0;32m    569\u001b[0m                                                method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    570\u001b[0m                                                disp\u001b[38;5;241m=\u001b[39mdisp,\n\u001b[0;32m    571\u001b[0m                                                maxiter\u001b[38;5;241m=\u001b[39mmaxiter,\n\u001b[0;32m    572\u001b[0m                                                callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    573\u001b[0m                                                retall\u001b[38;5;241m=\u001b[39mretall,\n\u001b[0;32m    574\u001b[0m                                                full_output\u001b[38;5;241m=\u001b[39mfull_output)\n\u001b[0;32m    575\u001b[0m \u001b[38;5;66;03m# Restore cov_type, cov_kwds and use_t\u001b[39;00m\n\u001b[0;32m    576\u001b[0m optim_settings\u001b[38;5;241m.\u001b[39mupdate(kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\optimizer.py:243\u001b[0m, in \u001b[0;36mOptimizer._fit\u001b[1;34m(self, objective, gradient, start_params, fargs, kwargs, hessian, method, maxiter, full_output, disp, callback, retall)\u001b[0m\n\u001b[0;32m    240\u001b[0m     fit_funcs\u001b[38;5;241m.\u001b[39mupdate(extra_fit_funcs)\n\u001b[0;32m    242\u001b[0m func \u001b[38;5;241m=\u001b[39m fit_funcs[method]\n\u001b[1;32m--> 243\u001b[0m xopt, retvals \u001b[38;5;241m=\u001b[39m func(objective, gradient, start_params, fargs, kwargs,\n\u001b[0;32m    244\u001b[0m                      disp\u001b[38;5;241m=\u001b[39mdisp, maxiter\u001b[38;5;241m=\u001b[39mmaxiter, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    245\u001b[0m                      retall\u001b[38;5;241m=\u001b[39mretall, full_output\u001b[38;5;241m=\u001b[39mfull_output,\n\u001b[0;32m    246\u001b[0m                      hess\u001b[38;5;241m=\u001b[39mhessian)\n\u001b[0;32m    248\u001b[0m optim_settings \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m: method, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_params\u001b[39m\u001b[38;5;124m'\u001b[39m: start_params,\n\u001b[0;32m    249\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m'\u001b[39m: maxiter, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull_output\u001b[39m\u001b[38;5;124m'\u001b[39m: full_output,\n\u001b[0;32m    250\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m'\u001b[39m: disp, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfargs\u001b[39m\u001b[38;5;124m'\u001b[39m: fargs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m'\u001b[39m: callback,\n\u001b[0;32m    251\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretall\u001b[39m\u001b[38;5;124m'\u001b[39m: retall, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_fit_funcs\u001b[39m\u001b[38;5;124m\"\u001b[39m: extra_fit_funcs}\n\u001b[0;32m    252\u001b[0m optim_settings\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\optimizer.py:660\u001b[0m, in \u001b[0;36m_fit_lbfgs\u001b[1;34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m approx_grad:\n\u001b[0;32m    658\u001b[0m     func \u001b[38;5;241m=\u001b[39m f\n\u001b[1;32m--> 660\u001b[0m retvals \u001b[38;5;241m=\u001b[39m optimize\u001b[38;5;241m.\u001b[39mfmin_l_bfgs_b(func, start_params, maxiter\u001b[38;5;241m=\u001b[39mmaxiter,\n\u001b[0;32m    661\u001b[0m                                  callback\u001b[38;5;241m=\u001b[39mcallback, args\u001b[38;5;241m=\u001b[39mfargs,\n\u001b[0;32m    662\u001b[0m                                  bounds\u001b[38;5;241m=\u001b[39mbounds, disp\u001b[38;5;241m=\u001b[39mdisp,\n\u001b[0;32m    663\u001b[0m                                  \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kwargs)\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_output:\n\u001b[0;32m    666\u001b[0m     xopt, fopt, d \u001b[38;5;241m=\u001b[39m retvals\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:277\u001b[0m, in \u001b[0;36mfmin_l_bfgs_b\u001b[1;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[0;32m    267\u001b[0m callback \u001b[38;5;241m=\u001b[39m _wrap_callback(callback)\n\u001b[0;32m    268\u001b[0m opts \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxcor\u001b[39m\u001b[38;5;124m'\u001b[39m: m,\n\u001b[0;32m    269\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mftol\u001b[39m\u001b[38;5;124m'\u001b[39m: factr \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mfinfo(\u001b[38;5;28mfloat\u001b[39m)\u001b[38;5;241m.\u001b[39meps,\n\u001b[0;32m    270\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgtol\u001b[39m\u001b[38;5;124m'\u001b[39m: pgtol,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m'\u001b[39m: callback,\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxls\u001b[39m\u001b[38;5;124m'\u001b[39m: maxls}\n\u001b[1;32m--> 277\u001b[0m res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args\u001b[38;5;241m=\u001b[39margs, jac\u001b[38;5;241m=\u001b[39mjac, bounds\u001b[38;5;241m=\u001b[39mbounds,\n\u001b[0;32m    278\u001b[0m                        \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopts)\n\u001b[0;32m    279\u001b[0m d \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrad\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjac\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    280\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    281\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfuncalls\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnfev\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    282\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnit\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnit\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    283\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwarnflag\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[0;32m    284\u001b[0m f \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfun\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:441\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    433\u001b[0m _lbfgsb\u001b[38;5;241m.\u001b[39msetulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr, pgtol, wa,\n\u001b[0;32m    434\u001b[0m                iwa, task, lsave, isave, dsave, maxls, ln_task)\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 441\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m func_and_grad(x)\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[0;32m    444\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:344\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x(x)\n\u001b[1;32m--> 344\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:295\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 295\u001b[0m         fx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapped_fun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n\u001b[0;32m    296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m fx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_f:\n\u001b[0;32m    297\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:21\u001b[0m, in \u001b[0;36m_wrapper_fun.<locals>.wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     17\u001b[0m ncalls[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m fx \u001b[38;5;241m=\u001b[39m fun(np\u001b[38;5;241m.\u001b[39mcopy(x), \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:534\u001b[0m, in \u001b[0;36mLikelihoodModel.fit.<locals>.f\u001b[1;34m(params, *args)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mf\u001b[39m(params, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m--> 534\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloglike(params, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m/\u001b[39m nobs\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:940\u001b[0m, in \u001b[0;36mMLEModel.loglike\u001b[1;34m(self, params, *args, **kwargs)\u001b[0m\n\u001b[0;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m complex_step:\n\u001b[0;32m    938\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minversion_method\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m INVERT_UNIVARIATE \u001b[38;5;241m|\u001b[39m SOLVE_LU\n\u001b[1;32m--> 940\u001b[0m loglike \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssm\u001b[38;5;241m.\u001b[39mloglike(complex_step\u001b[38;5;241m=\u001b[39mcomplex_step, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    942\u001b[0m \u001b[38;5;66;03m# Koopman, Shephard, and Doornik recommend maximizing the average\u001b[39;00m\n\u001b[0;32m    943\u001b[0m \u001b[38;5;66;03m# likelihood to avoid scale issues, but the averaging is done\u001b[39;00m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;66;03m# automatically in the base model `fit` method\u001b[39;00m\n\u001b[0;32m    945\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loglike\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py:1001\u001b[0m, in \u001b[0;36mKalmanFilter.loglike\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;124;03mCalculate the loglikelihood associated with the statespace model.\u001b[39;00m\n\u001b[0;32m    987\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    997\u001b[0m \u001b[38;5;124;03m    The joint loglikelihood.\u001b[39;00m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    999\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconserve_memory\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1000\u001b[0m                   MEMORY_CONSERVE \u001b[38;5;241m^\u001b[39m MEMORY_NO_LIKELIHOOD)\n\u001b[1;32m-> 1001\u001b[0m kfilter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1002\u001b[0m loglikelihood_burn \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloglikelihood_burn\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1003\u001b[0m                                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloglikelihood_burn)\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconserve_memory\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m&\u001b[39m MEMORY_NO_LIKELIHOOD):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py:921\u001b[0m, in \u001b[0;36mKalmanFilter._filter\u001b[1;34m(self, filter_method, inversion_method, stability_method, conserve_memory, filter_timing, tolerance, loglikelihood_burn, complex_step)\u001b[0m\n\u001b[0;32m    918\u001b[0m kfilter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kalman_filters[prefix]\n\u001b[0;32m    920\u001b[0m \u001b[38;5;66;03m# Initialize the state\u001b[39;00m\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_state(prefix\u001b[38;5;241m=\u001b[39mprefix, complex_step\u001b[38;5;241m=\u001b[39mcomplex_step)\n\u001b[0;32m    923\u001b[0m \u001b[38;5;66;03m# Run the filter\u001b[39;00m\n\u001b[0;32m    924\u001b[0m kfilter()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\representation.py:1058\u001b[0m, in \u001b[0;36mRepresentation._initialize_state\u001b[1;34m(self, prefix, complex_step)\u001b[0m\n\u001b[0;32m   1056\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialization\u001b[38;5;241m.\u001b[39minitialized:\n\u001b[0;32m   1057\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInitialization is incomplete.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1058\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_statespaces[prefix]\u001b[38;5;241m.\u001b[39minitialize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialization,\n\u001b[0;32m   1059\u001b[0m                                          complex_step\u001b[38;5;241m=\u001b[39mcomplex_step)\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1061\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStatespace model not initialized.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mstatsmodels\\\\tsa\\\\statespace\\\\_representation.pyx:1373\u001b[0m, in \u001b[0;36mstatsmodels.tsa.statespace._representation.dStatespace.initialize\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstatsmodels\\\\tsa\\\\statespace\\\\_representation.pyx:1362\u001b[0m, in \u001b[0;36mstatsmodels.tsa.statespace._representation.dStatespace.initialize\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstatsmodels\\\\tsa\\\\statespace\\\\_initialization.pyx:288\u001b[0m, in \u001b[0;36mstatsmodels.tsa.statespace._initialization.dInitialization.initialize\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstatsmodels\\\\tsa\\\\statespace\\\\_initialization.pyx:406\u001b[0m, in \u001b[0;36mstatsmodels.tsa.statespace._initialization.dInitialization.initialize_stationary_stationary_cov\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstatsmodels\\\\tsa\\\\statespace\\\\_tools.pyx:1626\u001b[0m, in \u001b[0;36mstatsmodels.tsa.statespace._tools._dsolve_discrete_lyapunov\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Schur decomposition solver error."
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "model = sm.tsa.arima.ARIMA(train, order=(2,1,3))\n",
    "results_Arima = model.fit()\n",
    "print(results_Arima.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARIMA_predictions=results_Arima.forecast(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train,label='Training Data')\n",
    "plt.plot(test,label='Test Data')\n",
    "plt.plot(test.index,ARIMA_predictions,label='Predicted Data - ARIMA')\n",
    "plt.legend(loc='best')\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  mean_squared_error\n",
    "rmse = mean_squared_error(test['Avg spending'],ARIMA_predictions, squared=False)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(y_true, y_pred):\n",
    "    return np.mean((np.abs(y_true-y_pred))/(y_true))*100\n",
    "\n",
    "mape=MAPE(test['Avg spending'].values,ARIMA_predictions[0])\n",
    "print(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Those Model MAPE is less that 10%. Model is not capturing the trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Will use Exponential Smoothing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api                  import  ExponentialSmoothing\n",
    "\n",
    "model_TES = ExponentialSmoothing(train,trend='additive',seasonal='additive',initialization_method='estimated')\n",
    "model_TES = model_TES.fit(optimized=True)\n",
    "model_TES.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TES_predictions =  model_TES.forecast(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train,label='Training Data')\n",
    "plt.plot(test,label='Test Data')\n",
    "plt.plot(test.index,TES_predictions,label='Predicted Data - TES')\n",
    "plt.legend(loc='best')\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = mean_squared_error(test['Avg spending'],TES_predictions.values, squared=False)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape=MAPE(test['Avg spending'].values,TES_predictions.values)\n",
    "print(mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_TES = ExponentialSmoothing(train,trend='additive',seasonal='additive',initialization_method='estimated')\n",
    "model_TES = model_TES.fit(smoothing_level=0.9542595,smoothing_trend=0.00607340,smoothing_seasonal=0.00158913,optimized=False)\n",
    "model_TES.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TES_predictions =  model_TES.forecast(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train,label='Training Data')\n",
    "plt.plot(test,label='Test Data')\n",
    "plt.plot(test.index,TES_predictions,label='Predicted Data - TES')\n",
    "plt.legend(loc='best')\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = mean_squared_error(test['Avg spending'],TES_predictions.values, squared=False)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape=MAPE(test['Avg spending'].values,TES_predictions.values)\n",
    "print(mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = test['Avg spending'].values-TES_predictions.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.gofplots        import  qqplot\n",
    "qqplot(residuals,line=\"s\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### residual points are falling approximately along this reference line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast Using Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_TES = ExponentialSmoothing(df,trend='additive',seasonal='additive',initialization_method='estimated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_TES = model_TES.fit(smoothing_level=0.9542595,smoothing_trend=0.00607340,smoothing_seasonal=0.00158913,optimized=False)\n",
    "model_TES.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast= model_TES.forecast(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df,label='Data')\n",
    "plt.plot(forecast,label='forecast - TES')\n",
    "plt.legend(loc='best')\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ML_1_40_MARKS_SET_2_EXAM_Paper.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
